{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84895f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of the dataset: (2154, 9)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = '../Dataset_Raw.json'\n",
    "\n",
    "df = pd.read_json(input_file_path)\n",
    "\n",
    "print(f\"Initial shape of the dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beec0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_labels(label_list):\n",
    "    if isinstance(label_list, list):\n",
    "        # Using .title() to capitalize the first letter of each word\n",
    "        return [str(item).title() for item in label_list]\n",
    "    return label_list # Return as-is if it's not a list (e.g., NaN)\n",
    "\n",
    "label_columns = [f'A_{i}' for i in range(1, 8)]\n",
    "for col in label_columns:\n",
    "    df[col] = df[col].apply(standardize_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b165c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Removed 4 rows with null labels.\n",
      "Shape after dropping nulls: (2150, 9)\n"
     ]
    }
   ],
   "source": [
    "initial_rows = len(df)\n",
    "df.dropna(subset=label_columns, inplace=True)\n",
    "rows_after_na = len(df)\n",
    "print(f\"\\n Removed {initial_rows - rows_after_na} rows with null labels.\")\n",
    "print(f\"Shape after dropping nulls: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ee2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 214 duplicate text entries.\n",
      "Shape after dropping duplicates: (1936, 9)\n"
     ]
    }
   ],
   "source": [
    "rows_before_duplicates = len(df)\n",
    "df.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "rows_after_duplicates = len(df)\n",
    "print(f\"\\nRemoved {rows_before_duplicates - rows_after_duplicates} duplicate text entries.\")\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c2d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 1 rows where 'Login Issue' was the Level 1 label in any annotator column.\n",
      "Shape after dropping 'Login Issue' rows: (1935, 9)\n"
     ]
    }
   ],
   "source": [
    "initial_rows = len(df)\n",
    "rows_to_drop = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for col in label_columns:\n",
    "        labels = row[col]\n",
    "        # Check if it's a list, not empty, and the first element is 'Login Issue'\n",
    "        if isinstance(labels, list) and len(labels) > 0 and labels[0] == 'Login Issue':\n",
    "            rows_to_drop.append(index)\n",
    "            break # Add the index and move to the next row\n",
    "\n",
    "# Drop the identified rows\n",
    "df.drop(index=rows_to_drop, inplace=True)\n",
    "rows_after_dropping_login_issue = len(df)\n",
    "\n",
    "print(f\"\\nRemoved {initial_rows - rows_after_dropping_login_issue} rows where 'Login Issue' was the Level 1 label in any annotator column.\")\n",
    "print(f\"Shape after dropping 'Login Issue' rows: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1d7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Re-indexed the 'id' column to be sequential.\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True) # First, reset the DataFrame index\n",
    "df['id'] = [f'{i+1:04d}' for i in range(len(df))]\n",
    "print(\"\\nStep 4: Re-indexed the 'id' column to be sequential.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08fa395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Process Complete ---\n",
      "Final clean dataset has 1935 samples.\n",
      "Cleaned data successfully saved to: Dataset_Clean.json\n"
     ]
    }
   ],
   "source": [
    "output_file_path = '../Dataset_Clean.json'\n",
    "\n",
    "df.to_json(output_file_path, orient='records', indent=4)\n",
    "print(\"\\n--- Cleaning Process Complete ---\")\n",
    "print(f\"Final clean dataset has {len(df)} samples.\")\n",
    "print(f\"Cleaned data successfully saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0f536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prutech_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
